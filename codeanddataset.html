<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>数据集和源码</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>安徽大学—结构模式与视觉学习研究组 (AHU-SPVL Group)</h1>
</div>




  
  
  
  
  
<h2>Code and Dataset</h2> 

 
  
	<ul>
		<li>
			<p><a href="">Long-term Frame-Event Visual Tracking: Benchmark Dataset and Baseline</a> <br />
				Xiao Wang, Ju Huang, Shiao Wang, Chuanming Tang, Bo Jiang, Yonghong Tian, Jin Tang, Bin Luo<br />
				<i>arXiv preprint arXiv:2403.05839 (2024).</i>
				[<a href="https://github.com/Event-AHU/FELT_SOT_Benchmark">Code</a>]
				[<a href="https://github.com/Event-AHU/FELT_SOT_Benchmark">Dataset</a>]
			</p>
		</li>
	</ul>

  <ul>
  	<li>
  		<p><a href="">Tiny Object Tracking: A Large-scale Dataset and A Baseline</a> <br />
  			Yabin Zhu, Chenglong Li, Yao Liu, Xiao Wang, Jin Tang, Bin Luo, Zhixiang Huang<br />
  			<i>IEEE Transactions on Neural Networks and Learning Systems (IEEE TNNLS), 2023. </i>
  			[<a href="https://github.com/ZYB0726/MKDNet">Code</a>]
  			[<a href="https://github.com/ZYB0726/MKDNet">Dataset</a>]
  		</p>
  	</li>
  </ul>

	<ul>
		<li>
			<p><a href="">Event Stream-based Visual Object Tracking: A High-Resolution Benchmark Dataset and A Novel Baseline</a> <br />
				Xiao Wang, Shiao Wang, Chuanming Tang, Lin Zhu, Bo Jiang, Yonghong Tian, Jin Tang<br />
				<i>CVPR-2024, arXiv 2309.14611</i>
				[<a href="https://github.com/Event-AHU/EventVOT_Benchmark">Code</a>]
				[<a href="https://github.com/Event-AHU/EventVOT_Benchmark">Dataset</a>]
			</p>
		</li>
	</ul>

	<ul>
		<li>
			<p><a href="">Revisiting Color-Event based Tracking: A Unified Network, Dataset, and Metric</a> <br />
				Chuanming Tang, Xiao Wang*, Ju Huang, Bo Jiang, Lin Zhu, Jianlin Zhang*, Yaowei Wang, Yonghong Tian<br />
				<i>arXiv pre-print, arXiv:2211.11010</i>
				[<a href="https://github.com/Event-AHU/COESOT">Code</a>]
				[<a href="https://github.com/Event-AHU/COESOT">Dataset</a>]
			</p>
		</li>
	</ul>
	
	<ul>
		<li>
			<p><a href="">Criteria Comparative Learning for Real-scene Image Super-Resolution</a> <br />
				Yukai Shi, Hao Li, Sen Zhang, Zhijing Yang, Xiao Wang<br />
				<i>IEEE Transactions on Circuits and Systems for Video Technology, 2022</i>
				[<a href="https://github.com/House-Leo/RealSR-Zero">Code</a>]
				[<a href="https://github.com/House-Leo/RealSR-Zero">Dataset</a>]
			</p>
		</li>
	</ul>


  <ul>
  	<li>
  		<p><a href="">Learning Deep Blind Quality Assessment for Cartoon Images</a> <br />
  			Yuan Chen, Yang Zhao, Li Cao, Wei Jia, Xiaoping Liu<br />
  			<i>IEEE Transactions on Neural Networks and Learning Systems (IEEE TNNLS), 2021. </i>
  			[<a href="https://github.com/YCheno/DCIQA">Code</a>]
  			[<a href="https://github.com/YCheno/DCIQA">Dataset</a>]
  		</p>
  	</li>
  </ul>


  <ul>
  	<li>
  		<p><a href="">Blind Quality Assessment for Cartoon Images</a> <br />
  			Yuan Chen, Yang Zhao, Shujie Li, Wangmeng Zuo, Wei Jia, Xiaoping Liu<br />
  			<i>IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT), 2019. </i>
  			[<a href="https://github.com/YCheno/CBIQA">Code</a>]
  			[<a href="https://github.com/YCheno/CBIQA">Dataset</a>]
  		</p>
  	</li>
  </ul>



  
<!-- <ul> 
<li><p><a href="">code</a> <br />
 dataset<br />
<i>文章
  <a href=""></a>
  <a href=""></a>
</i></p>
</li>
</ul> 


  
<ul> 
<li><p><a href="">code</a> <br />
 dataset<br />
<i>文章
  <a href=""></a>
  <a href=""></a>
</i></p>
</li>
</ul>  -->


  



  
  
  
<br />
</ul>
<div id="footer">
<div id="footer-text">
<br>Page generated 2024-4-18, by 安徽大学—结构模式与视觉学习研究组 (AHU-SPVL Group), School of Computer Science and Technology, Anhui University.
</div>
</div>
</div>
</body>
</html>


  
  
  
  

  
  
  
  
  
  
